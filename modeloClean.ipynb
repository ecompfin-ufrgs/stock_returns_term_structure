{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39405063-7e46-41a0-80e2-c8a48c53fdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['R_HOME'] = r'C:\\Program Files\\R\\R-4.4.2'  # Ajuste o caminho conforme sua instalação\n",
    "os.environ['R_USER'] = r'C:\\Program Files\\R\\R-4.4.2'  # Opcional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250b12c1-3e7e-43bc-87cc-914408d9e3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rpy2.rinterface_lib.callbacks import logger as rpy2_logger\n",
    "from rpy2.robjects import r, pandas2ri\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from statsmodels.stats.diagnostic import het_breuschpagan, het_white, acorr_breusch_godfrey, het_arch, acorr_ljungbox\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.tsa.stattools import acf, adfuller\n",
    "import rpy2.robjects as ro\n",
    "from scipy.stats import ttest_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11431def-b31c-4235-853e-a4e9ad7c3c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desabilitar logs do R para evitar mensagens de erro no console\n",
    "rpy2_logger.setLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae0865d-1dc8-4aa0-b996-7154ae545cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dbd058-7b1b-4609-a74e-07dfcba44ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers=['VALE3.SA', \n",
    "'PETR4.SA', \n",
    "'ITUB4.SA', \n",
    "'PETR3.SA', \n",
    "'BBDC4.SA', \n",
    "'BBAS3.SA', \n",
    "'ELET3.SA', \n",
    "'B3SA3.SA', \n",
    "'WEGE3.SA', \n",
    "'SBSP3.SA', \n",
    "'ITSA4.SA', \n",
    "'ABEV3.SA', \n",
    "'BPAC11.SA', \n",
    "'EQTL3.SA', \n",
    "'RENT3.SA', \n",
    "'JBSS3.SA', \n",
    "'PRIO3.SA', \n",
    "'RADL3.SA', \n",
    "'SUZB3.SA', \n",
    "'EMBR3.SA', \n",
    "'RAIL3.SA', \n",
    "'VBBR3.SA', \n",
    "'BBSE3.SA', \n",
    "'GGBR4.SA', \n",
    "'CMIG4.SA', \n",
    "'BRFS3.SA', \n",
    "'VIVT3.SA', \n",
    "'BBDC3.SA', \n",
    "'ENEV3.SA', \n",
    "'HAPV3.SA', \n",
    "'CPLE6.SA', \n",
    "'KLBN11.SA', \n",
    "'LREN3.SA', \n",
    "'TOTS3.SA', \n",
    "'CSAN3.SA', \n",
    "'ENGI11.SA', \n",
    "'TIMS3.SA', \n",
    "'CCRO3.SA', \n",
    "'ELET6.SA', \n",
    "'HYPE3.SA', \n",
    "'EGIE3.SA', \n",
    "'SANB11.SA', \n",
    "'STBP3.SA', \n",
    "'TRPL4.SA', \n",
    "'CSNA3.SA', \n",
    "'MULT3.SA', \n",
    "'TAEE11.SA', \n",
    "'FLRY3.SA', \n",
    "'GOAU4.SA', \n",
    "'CPFE3.SA', \n",
    "'AZZA3.SA', \n",
    "'CYRE3.SA', \n",
    "'BRAP4.SA', \n",
    "'BRKM5.SA', \n",
    "'CRFB3.SA', \n",
    "'MRFG3.SA', \n",
    "'MGLU3.SA', \n",
    "'IRBR3.SA', \n",
    "'SMTO3.SA', \n",
    "'SLCE3.SA', \n",
    "'USIM5.SA', \n",
    "'YDUQ3.SA', \n",
    "'MRVE3.SA', \n",
    "'COGN3.SA', \n",
    "'BEEF3.SA', \n",
    "'AZUL4.SA', \n",
    "'EZTC3.SA', \n",
    "'ALPA4.SA', \n",
    "'CVCB3.SA',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b136a3-99a5-4949-995a-d115759d75f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdi_data_train = pd.read_csv('SELICTRAIN.csv',sep=';', parse_dates=['Date'],dayfirst=True)\n",
    "cdi_data_train.set_index('Date', inplace=True)\n",
    "cdi_data_train.index = pd.to_datetime(cdi_data_train.index, dayfirst=True)\n",
    "cdi_data_train['CDI_Return'] = cdi_data_train['return'].str.replace(',', '.').astype(float)\n",
    "cdi_data_train.drop(columns=['return'], inplace=True)\n",
    "#cdi_data_train['CDI_Return']=np.log(1+cdi_data_train['CDI_Return'])\n",
    "\n",
    "\n",
    "cdi_data_forecast = pd.read_csv('SELICFORECAST.csv',sep=';', parse_dates=['Date'],dayfirst=True)\n",
    "cdi_data_forecast.set_index('Date', inplace=True)\n",
    "cdi_data_forecast.index = pd.to_datetime(cdi_data_forecast.index, dayfirst=True)\n",
    "cdi_data_forecast['CDI_Return'] = cdi_data_forecast['return'].str.replace(',', '.').astype(float)\n",
    "cdi_data_forecast.drop(columns=['return'], inplace=True)\n",
    "#cdi_data_forecast['CDI_Return']=np.log(1+cdi_data_forecast['CDI_Return'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9858caf-c686-4d5c-b146-b82ff0f17af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_train = '2019-10-01'\n",
    "end_train = '2023-04-10'\n",
    "start_forecasting = '2023-04-06'\n",
    "end_forecasting = '2024-10-03'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea149a8-9fb0-4e29-82ee-29a543a86f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "market_train = yf.download('^BVSP', start=start_train, end=end_train)['Adj Close'].pct_change().dropna()\n",
    "#market_train= np.log(market_train).diff().dropna()\n",
    "market_forecast = yf.download('^BVSP', start=start_forecasting, end=end_forecasting)['Adj Close'].pct_change().dropna()\n",
    "#market_forecast= np.log(market_forecast).diff().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac5dd24-8eb6-45dd-953c-95407bfcbdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdi_data_train = cdi_data_train.loc[market_train.index]\n",
    "cdi_data_forecast = cdi_data_forecast.loc[market_forecast.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aab2f65-0e3c-4d13-b4c0-e147fbd934fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "market_excess_train=(market_train-cdi_data_train['CDI_Return'])*100\n",
    "market_excess_forecast=(market_forecast-cdi_data_forecast['CDI_Return'])*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583e6dfc-a42e-4042-902f-f2f0a404b0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_excess_train=[]\n",
    "stock_excess_forecast=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c7c4a6-001e-4950-b29c-1e0a5e20e23a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for ticker in tickers:\n",
    "    stock_train=yf.download(ticker, start=start_train, end=end_train)['Adj Close'].pct_change().dropna()#.pct_change()\n",
    "    #stock_train=np.log(stock_train).diff().dropna()\n",
    "\n",
    "    \n",
    "    data= pd.DataFrame({\n",
    "        'Ticker': ticker,\n",
    "        'Stock_Return': stock_train,\n",
    "        'CDI_Return': cdi_data_train['CDI_Return']\n",
    "    }).dropna()\n",
    "\n",
    "    data['Stock_Excess'] = ((data['Stock_Return'] - data['CDI_Return']))*100\n",
    "\n",
    "    stock_excess_train.append(data)\n",
    "\n",
    "    #forecast\n",
    "    stock_forecast=yf.download(ticker, start=start_forecasting, end=end_forecasting)['Adj Close'].pct_change().dropna()\n",
    "    #stock_forecast=np.log(stock_forecast).diff().dropna()\n",
    "\n",
    "    \n",
    "    data_forecast= pd.DataFrame({\n",
    "        'Ticker': ticker,\n",
    "        'Stock_Return': stock_forecast,\n",
    "        'CDI_Return': cdi_data_forecast['CDI_Return']\n",
    "    }).dropna()\n",
    "\n",
    "    data_forecast['Stock_Excess'] = ((data_forecast['Stock_Return'] - data_forecast['CDI_Return']))*100\n",
    "\n",
    "    stock_excess_forecast.append(data_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775292d1-e0fd-48ed-9c5b-7391176f8796",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_excess_train = pd.concat(stock_excess_train)\n",
    "stock_excess_train = stock_excess_train[['Ticker', 'Stock_Excess']]\n",
    "stock_excess_forecast = pd.concat(stock_excess_forecast)\n",
    "stock_excess_forecast = stock_excess_forecast[['Ticker', 'Stock_Excess']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1294e6-e61b-465f-8369-e180963773a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar valores ausentes nos dados\n",
    "for ticker in tickers:\n",
    "    stock_train = yf.download(ticker, start=start_train, end=end_train)['Adj Close']\n",
    "    if stock_train.isnull().any():\n",
    "        print(f\"Ticker {ticker} contém valores ausentes.\")\n",
    "    else:\n",
    "        print(f\"Ticker {ticker} está limpo.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ab053a-c2be-43d0-a3d5-6404f1e9e607",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tests_capm=[]\n",
    "params_capm=[]\n",
    "\n",
    "for ticker in stock_excess_train['Ticker'].unique():\n",
    "    ticker_excess_train = stock_excess_train.loc[stock_excess_train['Ticker'] == ticker]['Stock_Excess']\n",
    "    market_excess = market_excess_train.loc[ticker_excess_train.index]\n",
    "    \n",
    "    # Ajusta o modelo CAPM Clássico\n",
    "    #adicionar lags no x e no y\n",
    "    X_capm = sm.add_constant(market_excess_train.rename('Market_excess_train'))\n",
    "    model_capm = sm.OLS(ticker_excess_train, X_capm).fit(cov_type='HAC', cov_kwds={'maxlags': int(np.sqrt(len(ticker_excess_train)))})\n",
    "\n",
    "   \n",
    "    #juntar os parâmetros do capm\n",
    "    params_capm.append({\n",
    "        'Ticker':ticker,\n",
    "        'Alpha estimado':model_capm.params.get('const', 0),\n",
    "        'Beta estimado':model_capm.params.get('Market_excess_train',0),\n",
    "        'P-Valor Alfa estimado':model_capm.pvalues['const'],\n",
    "        'P-Valor Beta estimado':model_capm.pvalues['Market_excess_train']\n",
    "    })\n",
    "    # Teste de White (Heterocedasticidade geral)\n",
    "    white_test = het_white(model_capm.resid, model_capm.model.exog)\n",
    "    white_pvalue = white_test[1]\n",
    "\n",
    "    # Teste de Durbin-Watson\n",
    "    dw_stat = durbin_watson(model_capm.resid)\n",
    "\n",
    "    # EFEITOS ARCH ARCH-LM\n",
    "    arch_test = het_arch(model_capm.resid.dropna(), nlags=1, store=False)\n",
    "    arch_pvalue = arch_test[1]\n",
    "\n",
    "\n",
    "    \n",
    "    #Juntar os testes de resíduos do CAPM\n",
    "    tests_capm.append({\n",
    "        'Ticker':ticker,\n",
    "        'White':white_pvalue,\n",
    "        'Durbin-Watson':dw_stat,\n",
    "        'P-Valor Alfa':model_capm.pvalues['const'],\n",
    "        'ARCH LM':arch_pvalue,\n",
    "        'P-Valor Beta':model_capm.pvalues['Market_excess_train']\n",
    "        \n",
    "    })\n",
    "\n",
    "tests_capm_df = pd.DataFrame(tests_capm)\n",
    "tests_capm_df.to_excel('tests_capm.xlsx', index=False)\n",
    "params_capm_df = pd.DataFrame(params_capm)\n",
    "params_capm_df.to_excel('params_capm.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ddd791-c009-476c-89c8-a185c4984fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ativar a interface R-Python\n",
    "pandas2ri.activate()\n",
    "\n",
    "# Inicializar listas para coletar os resultados\n",
    "forecast_garchm = []\n",
    "tests_garchm = []\n",
    "params_garchm = []\n",
    "\n",
    "# Configurar o R para usar o idioma inglês e evitar problemas de codificação\n",
    "ro.r('Sys.setlocale(\"LC_ALL\", \"C\")')\n",
    "ro.r('Sys.setenv(LANG = \"en\")')\n",
    "\n",
    "# Loop através de cada ticker\n",
    "for ticker in stock_excess_train['Ticker'].unique():\n",
    "    ticker_data = stock_excess_train.loc[stock_excess_train['Ticker'] == ticker, 'Stock_Excess']\n",
    "    market_excess = market_excess_train.loc[ticker_data.index]\n",
    "    \n",
    "    # Converter os dados para objetos R\n",
    "    r_returns = pandas2ri.py2rpy(pd.Series(ticker_data.values, name=\"returns\"))\n",
    "    r_market_excess = pandas2ri.py2rpy(pd.Series(market_excess.values, name=\"market\"))\n",
    "    ro.globalenv['returns'] = r_returns\n",
    "    ro.globalenv['market'] = r_market_excess\n",
    "\n",
    "    # Código R para ajustar o modelo e extrair os resultados\n",
    "    r_code = \"\"\"\n",
    "    library(rugarch)\n",
    "    library(lmtest)\n",
    "    library(FinTS)\n",
    "    \n",
    "    # Especificação do modelo GARCH-M com variável exógena\n",
    "    spec <- ugarchspec(\n",
    "        mean.model = list(\n",
    "            armaOrder = c(0, 0),\n",
    "            include.mean = TRUE,\n",
    "            archm = TRUE,\n",
    "            archpow = 1,\n",
    "            external.regressors = as.matrix(market)\n",
    "        ),\n",
    "        variance.model = list(\n",
    "            model = \"sGARCH\",\n",
    "            garchOrder = c(1,1)\n",
    "        ),\n",
    "        distribution.model = \"norm\"\n",
    "    )\n",
    "    \n",
    "    # Tentar ajustar o modelo\n",
    "    fit <- tryCatch(\n",
    "        ugarchfit(spec, data = returns),\n",
    "        error = function(e) { return(NULL) }\n",
    "    )\n",
    "    \n",
    "    # Verificar se o ajuste foi bem-sucedido\n",
    "    if (is.null(fit)) {\n",
    "        stop(\"Falha no ajuste do modelo.\")\n",
    "    }\n",
    "    \n",
    "    # Calcular a matriz de covariância robusta\n",
    "    cov_matrix <- vcov(fit, robust = TRUE)\n",
    "    params <- coef(fit)\n",
    "    std_errors <- sqrt(diag(cov_matrix))\n",
    "    t_values <- params / std_errors\n",
    "    p_values <- 2 * (1 - pnorm(abs(t_values)))\n",
    "\n",
    "    # Criar tabela de parâmetros\n",
    "    params_table <- data.frame(\n",
    "        Estimate = params,\n",
    "        Std_Error = std_errors,\n",
    "        t_value = t_values,\n",
    "        p_value = p_values\n",
    "    )\n",
    "    rownames(params_table) <- names(params)\n",
    "    \n",
    "    # Prever a volatilidade condicional\n",
    "    forecast <- ugarchforecast(fit, n.ahead = 373)\n",
    "    sigma_forecast <- as.numeric(sigma(forecast))\n",
    "    \n",
    "    # Testes de hipótese\n",
    "    std_residuals <- residuals(fit, standardize=TRUE)\n",
    "    ljung_box_test <- Box.test(std_residuals, lag=12, type=\"Ljung-Box\", fitdf=0)\n",
    "    arch_lm_test <- ArchTest(std_residuals, lags=1)\n",
    "    white_test <- bptest(lm(std_residuals ~ market + I(market^2)))\n",
    "\n",
    "    # Extrair AIC e BIC como valores numéricos\n",
    "    AIC_value <- as.numeric(infocriteria(fit)[[1]])\n",
    "    BIC_value <- as.numeric(infocriteria(fit)[[2]])\n",
    "\n",
    "    \n",
    "    # Retornar resultados\n",
    "    list(\n",
    "        params_table = params_table,\n",
    "        sigma_forecast = sigma_forecast,\n",
    "        ljung_box_p_value = ljung_box_test$p.value,\n",
    "        arch_lm_p_value = arch_lm_test$p.value,\n",
    "        white_pvalue = white_test$p.value,\n",
    "        AIC = AIC_value,\n",
    "        BIC = BIC_value\n",
    "    )\n",
    "    \"\"\"\n",
    "\n",
    "    # Executar o código R\n",
    "    try:\n",
    "        r_result = ro.r(r_code)\n",
    "        \n",
    "        # Verificar se o resultado foi gerado corretamente\n",
    "        if r_result is None:\n",
    "            print(f\"Erro ao processar o ticker {ticker}: Nenhum resultado gerado.\")\n",
    "            continue\n",
    "        \n",
    "        # Extrair os resultados\n",
    "        params_table = pd.DataFrame(ro.conversion.rpy2py(r_result.rx2('params_table')))\n",
    "        params_table['Parameter'] = params_table.index\n",
    "        params_table['Ticker'] = ticker\n",
    "        params_garchm.append(params_table)\n",
    "\n",
    "        \n",
    "        \n",
    "        sigma_forecast = np.array(r_result.rx2('sigma_forecast'))\n",
    "        forecast_df = pd.DataFrame({\n",
    "            'Ticker': ticker,\n",
    "            'Period': np.arange(1, len(sigma_forecast) + 1),\n",
    "            'Sigma_Forecast': sigma_forecast\n",
    "        })\n",
    "        forecast_garchm.append(forecast_df)\n",
    "        \n",
    "        ljung_box_p_value = r_result.rx2('ljung_box_p_value')[0]\n",
    "        arch_lm_p_value = r_result.rx2('arch_lm_p_value')[0]\n",
    "        white_pvalue = r_result.rx2('white_pvalue')[0]\n",
    "        AIC = float(r_result.rx2('AIC')[0])\n",
    "        BIC = float(r_result.rx2('BIC')[0])\n",
    "        \n",
    "        tests_garchm.append({\n",
    "            'Ticker': ticker,\n",
    "            'ljung_box_p_value': ljung_box_p_value,\n",
    "            'arch_lm_p_value': arch_lm_p_value,\n",
    "            'white_pvalue': white_pvalue,\n",
    "            'AIC': AIC,\n",
    "            'BIC': BIC\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao processar o ticker {ticker}: {e}\")\n",
    "        continue\n",
    "\n",
    "# Após o loop, salvar os resultados em arquivos Excel\n",
    "params_garchm_df = pd.concat(params_garchm, ignore_index=True)\n",
    "params_garchm_df.to_excel('params_garchm.xlsx', index=False)\n",
    "\n",
    "forecast_garchm_df = pd.concat(forecast_garchm, ignore_index=True)\n",
    "forecast_garchm_df.to_excel('forecast_garchm.xlsx', index=False)\n",
    "\n",
    "tests_garchm_df = pd.DataFrame(tests_garchm)\n",
    "tests_garchm_df.to_excel('tests_garchm.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5724288-7e51-4c3d-a6c0-18f78f2db131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resetar o índice para ter 'Date' como coluna\n",
    "#cdi_data_forecast_reset = cdi_data_forecast.reset_index()\n",
    "# Converter 'CDI_Return' em pontos percentuais\n",
    "#cdi_data_forecast_reset['CDI_Return_Percent'] = cdi_data_forecast_reset['CDI_Return'] * 100\n",
    "\n",
    "params_pivot=params_garchm_df.pivot(index='Ticker', columns='Parameter', values='Estimate').reset_index()\n",
    "\n",
    "market_excess_forecast_garchm_df = pd.DataFrame({\n",
    "    'Date': market_excess_forecast.index,\n",
    "    'Market_Excess': market_excess_forecast.values\n",
    "}).reset_index(drop=True)\n",
    "\n",
    "market_excess_forecast_garchm_df['Period'] = market_excess_forecast_garchm_df.index + 1  # Period começa em 1\n",
    "\n",
    "forecast_garchm_df = pd.merge(\n",
    "    forecast_garchm_df,\n",
    "    market_excess_forecast_garchm_df[['Period', 'Date', 'Market_Excess']],\n",
    "    on='Period',\n",
    "    how='left'\n",
    ")\n",
    "forecasts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1702bf6e-528d-4ad9-b1ec-0f4094147c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ticker in params_pivot['Ticker']:\n",
    "    # Obter os parâmetros para o ticker atual\n",
    "    params = params_pivot[params_pivot['Ticker'] == ticker].iloc[0]\n",
    "    mu = params.get('mu')\n",
    "    mxreg1 = params.get('mxreg1')\n",
    "    archm = params.get('archm')\n",
    "    \n",
    "    \n",
    "    # Obter as previsões de sigma para o ticker atual\n",
    "    sigma_forecast_ticker = forecast_garchm_df[forecast_garchm_df['Ticker'] == ticker].copy()\n",
    "        \n",
    "    # Aplicar a fórmula para calcular o retorno em excesso previsto\n",
    "    sigma_forecast_ticker['Retorno_Excesso_Previsto'] = (\n",
    "        mu + mxreg1 * sigma_forecast_ticker['Market_Excess'] + archm * sigma_forecast_ticker['Sigma_Forecast']\n",
    "    )\n",
    "    \n",
    "    # Adicionar o ticker e a data ao DataFrame\n",
    "    sigma_forecast_ticker['Ticker'] = ticker\n",
    "    sigma_forecast_ticker['Date'] = sigma_forecast_ticker['Date']\n",
    "    \n",
    "    # Selecionar as colunas relevantes\n",
    "    forecasts.append(sigma_forecast_ticker[['Ticker', 'Date', 'Retorno_Excesso_Previsto']])\n",
    "\n",
    "# Concatenar todos os DataFrames em um único DataFrame\n",
    "results_garchm_df = pd.concat(forecasts, ignore_index=True)\n",
    "\n",
    "# Salvar os resultados em um arquivo Excel\n",
    "results_garchm_df.to_excel('retorno_excesso_previsto.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4041e661-98c0-4b84-a307-e6cce7654f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mesclar com base na coluna 'Date'\n",
    "#forecasts_with_cdi = pd.merge(\n",
    "#    results_garchm_df,\n",
    " #   cdi_data_forecast_reset[['Date', 'CDI_Return_Percent']],\n",
    "  #  on='Date',\n",
    "  #  how='left'\n",
    "#)\n",
    "\n",
    "# Calcular o Retorno Total Previsto\n",
    "#forecasts_with_cdi['Retorno_Total_Previsto'] = (\n",
    "#    forecasts_with_cdi['Retorno_Excesso_Previsto'] + forecasts_with_cdi['CDI_Return_Percent']\n",
    "#)\n",
    "\n",
    "# Passo 4: Salvar os Resultados\n",
    "#forecasts_with_cdi.to_excel('retorno_total_previsto_garchm.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7364023f-39dc-4859-a1e3-fda4e1e11539",
   "metadata": {},
   "outputs": [],
   "source": [
    "retorno_excesso_capm = []\n",
    "\n",
    "# Criar um DataFrame com as previsões de excesso de mercado\n",
    "market_excess_forecast_capm_df = pd.DataFrame({\n",
    "    'Date': market_excess_forecast.index,\n",
    "    'Market_Excess': market_excess_forecast.values\n",
    "}).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Iterar sobre cada ticker para calcular o Retorno em Excesso Previsto\n",
    "for index, row in params_capm_df.iterrows():\n",
    "    ticker = row['Ticker']\n",
    "    alpha = row['Alpha estimado']\n",
    "    beta = row['Beta estimado']\n",
    "        \n",
    "    # Criar um DataFrame temporário para o ticker atual\n",
    "    ticker_forecast = pd.DataFrame({\n",
    "        'Date': market_excess_forecast_capm_df['Date'],\n",
    "        'Ticker': ticker,\n",
    "        'Market_Excess': market_excess_forecast_capm_df['Market_Excess']\n",
    "    })\n",
    "    \n",
    "    # Calcular o Retorno em Excesso Previsto\n",
    "    ticker_forecast['Retorno_Excesso_Previsto'] = alpha + beta * ticker_forecast['Market_Excess']\n",
    "    \n",
    "    # Adicionar o DataFrame temporário à lista\n",
    "    retorno_excesso_capm.append(ticker_forecast[['Ticker', 'Date', 'Retorno_Excesso_Previsto']])\n",
    "\n",
    "# Concatenar todos os DataFrames em um único DataFrame\n",
    "retorno_excesso_capm_df = pd.concat(retorno_excesso_capm, ignore_index=True)\n",
    "\n",
    "# Salvar os retornos em excesso do capm\n",
    "retorno_excesso_capm_df.to_excel('retorno_excesso_previsto_capm.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ded3032-ef0d-46d3-895d-0609090b06d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mesclar o Retorno em Excesso Previsto com os dados do CDI\n",
    "#forecasts_capm_with_cdi = pd.merge(\n",
    "   # retorno_excesso_capm_df,\n",
    "   # cdi_data_forecast_reset[['Date', 'CDI_Return_Percent']],\n",
    "  #  on='Date',\n",
    " #   how='left'\n",
    "#)\n",
    "# Calcular o Retorno Total Previsto\n",
    "#forecasts_capm_with_cdi['Retorno_Total_Previsto'] = (\n",
    " #   forecasts_capm_with_cdi['CDI_Return_Percent'] + forecasts_capm_with_cdi['Retorno_Excesso_Previsto']\n",
    "#)\n",
    "\n",
    "# Selecionar as colunas relevantes\n",
    "#retorno_total_capm_df = forecasts_capm_with_cdi[['Ticker', 'Date', 'Retorno_Total_Previsto']]\n",
    "\n",
    "# Salvar os resultados em um arquivo Excel\n",
    "#retorno_total_capm_df.to_excel('retorno_total_previsto_capm.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba1b13f-3627-4299-8682-f04b3c010e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotar o comparativo de retornos em excesso\n",
    "#for ticker in tickers:\n",
    "\n",
    "\n",
    " #   plt.figure(figsize=(14, 7))\n",
    "  #  plt.plot(\n",
    "   #     market_excess_forecast.index, \n",
    "    #    results_garchm_df['Retorno_Excesso_Previsto'][results_garchm_df['Ticker'] == ticker],\n",
    "     #   label='GARCH-M', \n",
    "      #  color='blue'\n",
    "    #)\n",
    "    \n",
    "    # Plotar os retornos em excesso previstos pelo CAPM\n",
    "    #plt.plot(\n",
    "     #   market_excess_forecast.index, \n",
    "      #  retorno_excesso_capm_df['Retorno_Excesso_Previsto'][retorno_excesso_capm_df['Ticker'] == ticker],\n",
    "       # label='CAPM', \n",
    "       # color='orange'\n",
    "    #)\n",
    "\n",
    "    # Plotar os retornos em excesso previstos pelo CAPM\n",
    "    #plt.plot(\n",
    "     #   market_excess_forecast.index, \n",
    "      #  stock_excess_forecast['Stock_Excess'][stock_excess_forecast['Ticker']==ticker],\n",
    "      #  label='real', \n",
    "      #  color='green'\n",
    "    #)\n",
    "    # Adicionar rótulos e título\n",
    "    #plt.xlabel('Data')\n",
    "    #plt.ylabel('Retorno em Excesso Previsto (%)')\n",
    "    #plt.title(f'Comparativo de Retornos em Excesso Previsto - {ticker}')\n",
    "    \n",
    "    # Adicionar legenda e grid\n",
    "    #plt.legend()\n",
    "    #plt.grid(True)\n",
    "    \n",
    "    # Ajustar layout e exibir o gráfico\n",
    "    #plt.tight_layout()\n",
    "    #plt.show()\n",
    "    #plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb07f724-bef8-4cdb-b884-005075b804ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir o nível de significância\n",
    "significance_level = 0.05\n",
    "\n",
    "# Filtrar os tickers que não apresentam heterocedasticidade e autocorrelação no modelo GARCH-M\n",
    "garchm_filtered = tests_garchm_df[\n",
    "    (tests_garchm_df['white_pvalue'] > significance_level) &\n",
    "    (tests_garchm_df['ljung_box_p_value'] > significance_level)\n",
    "]\n",
    "\n",
    "print(f\"\\nTickers que passaram os testes GARCH-M ({len(garchm_filtered)} tickers):\")\n",
    "print(garchm_filtered['Ticker'].tolist())\n",
    "\n",
    "# Filtrar os tickers que não apresentam heterocedasticidade e autocorrelação no modelo CAPM\n",
    "capm_filtered = tests_capm_df[\n",
    "    (tests_capm_df['White'] > significance_level) &\n",
    "    (tests_capm_df['Durbin-Watson'] >= 1.8915) &\n",
    "    (tests_capm_df['Durbin-Watson'] <= 2.1085)\n",
    "]\n",
    "\n",
    "print(f\"\\nTickers que passaram os testes CAPM ({len(capm_filtered)} tickers):\")\n",
    "print(capm_filtered['Ticker'].tolist())\n",
    "\n",
    "# Encontrar os tickers que passaram em ambos os modelos\n",
    "tickers_garchm = set(garchm_filtered['Ticker'])\n",
    "tickers_capm = set(capm_filtered['Ticker'])\n",
    "\n",
    "tickers_final = tickers_garchm.intersection(tickers_capm)\n",
    "\n",
    "# Converter para lista e ordenar\n",
    "tickers_final = sorted(list(tickers_final))\n",
    "\n",
    "print(f\"\\nTickers que não apresentam heterocedasticidade e autocorrelação em ambos os modelos GARCH-M e CAPM ({len(tickers_final)} tickers):\")\n",
    "print(tickers_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a30885-710b-4700-a1d7-b8c2e4997bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotar o comparativo de retornos em excesso apenas dos que não apresentam autocorrelação nem heterocedasticidade para ambos\n",
    "for ticker in tickers_final:\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    plt.plot(\n",
    "        market_excess_forecast.index, \n",
    "        results_garchm_df['Retorno_Excesso_Previsto'][results_garchm_df['Ticker'] == ticker],\n",
    "        label='GARCH-M', \n",
    "        color='blue'\n",
    "    )\n",
    "    \n",
    "    # Plotar os retornos em excesso previstos pelo CAPM\n",
    "    plt.plot(\n",
    "        market_excess_forecast.index, \n",
    "        retorno_excesso_capm_df['Retorno_Excesso_Previsto'][retorno_excesso_capm_df['Ticker'] == ticker],\n",
    "        label='CAPM', \n",
    "        color='orange'\n",
    "    )\n",
    "    \n",
    "    # Adicionar rótulos e título\n",
    "    plt.xlabel('Data')\n",
    "    plt.ylabel('Retorno em Excesso Previsto (%)')\n",
    "    plt.title(f'Comparativo de Retornos em Excesso Previsto - {ticker}')\n",
    "    \n",
    "    # Adicionar legenda e grid\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Ajustar layout e exibir o gráfico\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8072d533-28f5-45fc-ac63-78a83716324d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcula o RMSE e a significancia do RMSE entre o GARCH-M e o CAPM com os tickers em comum\n",
    "\n",
    "rmse=[]\n",
    "for ticker in tickers_final:\n",
    "\n",
    "    rmse_garchm=root_mean_squared_error(stock_excess_forecast['Stock_Excess'][stock_excess_forecast['Ticker']==ticker],results_garchm_df['Retorno_Excesso_Previsto'][results_garchm_df['Ticker'] == ticker])\n",
    "    rmse_capm=root_mean_squared_error(stock_excess_forecast['Stock_Excess'][stock_excess_forecast['Ticker']==ticker],retorno_excesso_capm_df['Retorno_Excesso_Previsto'][retorno_excesso_capm_df['Ticker'] == ticker])\n",
    "\n",
    "    # Calcular os erros quadrados de cada modelo\n",
    "    errors_garchm = (stock_excess_forecast['Stock_Excess'][stock_excess_forecast['Ticker']==ticker].values - results_garchm_df['Retorno_Excesso_Previsto'][results_garchm_df['Ticker'] == ticker].values) ** 2\n",
    "    errors_capm = (stock_excess_forecast['Stock_Excess'][stock_excess_forecast['Ticker']==ticker].values - retorno_excesso_capm_df['Retorno_Excesso_Previsto'][retorno_excesso_capm_df['Ticker'] == ticker].values) ** 2\n",
    "\n",
    "    # Realizar o teste t pareado entre os erros quadrados dos dois modelos\n",
    "    t_stat, p_value = ttest_rel(errors_garchm, errors_capm)\n",
    "    \n",
    "    rmse.append({\n",
    "        'Ticker': ticker,\n",
    "        'RMSE - GARCHM': rmse_garchm,\n",
    "        'RMSE - CAPM': rmse_capm,\n",
    "        't-statistic': t_stat,\n",
    "        'p-value': p_value\n",
    "    })\n",
    "\n",
    "rmse_df = pd.DataFrame(rmse)\n",
    "rmse_df.to_excel('RMSE.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adc3def-13fc-4a87-a642-6d19f4bdb679",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcula o RMSE do GARCH-M para todos os tickers que limparam\n",
    "\n",
    "rmse_garchm=[]\n",
    "for ticker in tickers_garchm:\n",
    "\n",
    "    rmse_g=root_mean_squared_error(stock_excess_forecast['Stock_Excess'][stock_excess_forecast['Ticker']==ticker],results_garchm_df['Retorno_Excesso_Previsto'][results_garchm_df['Ticker'] == ticker])\n",
    "    \n",
    "    rmse_garchm.append({\n",
    "        'Ticker': ticker,\n",
    "        'RMSE - GARCHM': rmse_g,\n",
    "    })\n",
    "\n",
    "rmse_garchm_df = pd.DataFrame(rmse_garchm)\n",
    "rmse_garchm_df.to_excel('RMSE_GARCHM.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa45c2e-30ec-4a55-b218-11a2a90b157c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista para armazenar os resultados\n",
    "adf_stock_results = []\n",
    "adf_market_results = []\n",
    "\n",
    "# Aplicar o teste ADF para o excesso de retorno de mercado\n",
    "result_market = adfuller(market_excess_train, autolag='AIC')\n",
    "adf_market_results.append({\n",
    "    'ADF Statistic': result_market[0],\n",
    "    'p-value': result_market[1],\n",
    "    'Lags Used': result_market[2],\n",
    "    'Number of Observations': result_market[3],\n",
    "    'Critical Values': result_market[4],\n",
    "    'Stationary': result_market[1] < 0.05  # True se p-value < 0.05\n",
    "})\n",
    "\n",
    "# Aplicar o teste ADF para cada série de ativos\n",
    "for ticker in tickers:\n",
    "    # Filtrar os retornos da série do ticker\n",
    "    ticker_returns = stock_excess_train.loc[stock_excess_train['Ticker'] == ticker, 'Stock_Excess']\n",
    "    # Executar o teste ADF\n",
    "    result = adfuller(ticker_returns, autolag='AIC')\n",
    "    \n",
    "    # Coletar os resultados\n",
    "    adf_stock_results.append({\n",
    "        'Ticker': ticker,\n",
    "        'ADF Statistic': result[0],\n",
    "        'p-value': result[1],\n",
    "        'Lags Used': result[2],\n",
    "        'Number of Observations': result[3],\n",
    "        'Critical Values': result[4],\n",
    "        'Stationary': result[1] < 0.05  # True se p-value < 0.05\n",
    "    })\n",
    "\n",
    "# Converter os resultados em DataFrame\n",
    "adf_stock_results_df = pd.DataFrame(adf_stock_results)\n",
    "adf_market_results_df = pd.DataFrame(adf_market_results)\n",
    "\n",
    "# Salvar os resultados em Excel\n",
    "adf_stock_results_df.to_excel('ADF_Stock.xlsx', index=False)\n",
    "adf_market_results_df.to_excel('ADF_Market.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbbab0a-ca87-4b43-a9b0-0337b1e9c4be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
